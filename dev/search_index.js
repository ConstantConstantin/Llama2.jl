var documenterSearchIndex = {"docs":
[{"location":"devs/#Developer's-Corner","page":"Developer's Corner","title":"Developer's Corner","text":"You want to understand how this package works or modify the code you are running? Here the necessary tools are provided and explained.","category":"section"},{"location":"devs/#Tokenizer","page":"Developer's Corner","title":"Tokenizer","text":"Explain Tokenizer and surrounding functionality.","category":"section"},{"location":"devs/#Transformer","page":"Developer's Corner","title":"Transformer","text":"Explain Transformer and surrounding functionality.","category":"section"},{"location":"#Llama2.jl","page":"Home","title":"Llama2.jl","text":"","category":"section"},{"location":"#What-is-Llama2?","page":"Home","title":"What is Llama2?","text":"LLama2 is a family of pre-trained LLMs by Meta AI. More information can be found at: https://www.llama.com/","category":"section"},{"location":"#What-is-Llama2.jl?","page":"Home","title":"What is Llama2.jl?","text":"Llama2.jl can inference a given model from within julia. For this cause you will have to provide your own model checkpoint. This project follows the procedure outlined by the run.c file from llama2.c.","category":"section"},{"location":"#Getting-started","page":"Home","title":"Getting started","text":"Clone the repository to a desired location:\n\ncd /PATH/TO/DESIRED/LOCATION/\ngit clone git@github.com:ConstantConstantin/Llama2.git\n\nStart julia, activate a desired environment and add the package; it can then be loaded in your session:\n\n(@v1.11) pkg> activate .\n  Activating new project at `PATH/TO/MY/ENVIRONMENT/myLlama2`\n\n(myLlama2) pkg> add /PATH/TO/DESIRED/LOCATION/Llama2/\n     Cloning git-repo `/PATH/TO/DESIRED/LOCATION/Llama2`\n    Updating git-repo `/PATH/TO/DESIRED/LOCATION/Llama2`\n    Updating registry at `~/.julia/registries/General.toml`\n   Resolving package versions...\n    Updating `PATH/TO/MY/ENVIRONMENT/Project.toml`\n  [0e620e9f] + Llama2 v1.0.0-DEV `/PATH/TO/DESIRED/LOCATION/Llama2#aj/docs`\n    Updating `PATH/TO/MY/ENVIRONMENT/Manifest.toml`\n  [0e620e9f] + Llama2 v1.0.0-DEV `/PATH/TO/DESIRED/LOCATION/Llama2#aj/docs`\nPrecompiling project...\n  1 dependency successfully precompiled in 1 seconds\n\njulia> using Llama2\n\n","category":"section"},{"location":"#Llama2.Config","page":"Home","title":"Llama2.Config","text":"Config\n\nCreate a Config containing 7 Int32. These describe meta-data to read values from an input file.\n\nDeveloper Notes\n\nThis is an internal struct.\n\n\n\n\n\n","category":"type"},{"location":"#Llama2.RunState","page":"Home","title":"Llama2.RunState","text":"RunState\n\nCreate a RunState containing several Float32 containers. These reflect the state of the Transformer at run-time.\n\nDeveloper Notes\n\nThis is an internal struct.\n\n\n\n\n\n","category":"type"},{"location":"#Llama2.TokenIndex","page":"Home","title":"Llama2.TokenIndex","text":"TokenIndex(str::String, id::Integer)\n\nCreate a TokenIndex from a string and an integer identifier.\n\nThe byte sequence is converted to String and the ID is converted to Int16.   Throw a DomainError if id â‰¤ 0.\n\nExamples\n\njulia> using Llama2;\n\njulia> TokenIndex(\"Julia\", 1)\nTokenIndex(\"Julia\", 1)\n\njulia> TokenIndex(\"Julia\", -1)\nERROR: DomainError with Token index must be > 0.\n[...]\n\nDeveloper Notes\n\nThis is an internal struct.\n\n\n\n\n\n","category":"type"},{"location":"#Llama2.Tokenizer","page":"Home","title":"Llama2.Tokenizer","text":"Tokenizer\n\nConstruct a tokenizer storing vocabulary entries, scores, and byte-piece mappings.\n\nConstructors\n\nTokenizer(vocab, vocab_scores, sorted_vocab, vocab_size, max_token_length, byte_pieces)   Construct a tokenizer directly from the provided fields.   Validate that max_token_length > 0 and that byte_pieces has length 256.\nTokenizer(path::String, vocab_size::Integer)   Load a tokenizer from a binary file.\n\nFields\n\nvocab: Token string sequences.  \nvocab_scores: Scores for each token.  \nsorted_vocab: Sorted token indices.  \nvocab_size: Number of vocabulary entries.  \nmax_token_length: Maximum token length in bytes.  \nbyte_pieces: Byte mapping (length 256).\n\n\n\n\n\n","category":"type"},{"location":"#Llama2.Transformer-Tuple{String}","page":"Home","title":"Llama2.Transformer","text":"Transformer(path::String)\n\nLoad a binary file with location path and construct a Transformer from its content. The file is expected to have a header of 7 Int32 values followed by Float32 data.\n\nExample\n\njulia> t = Llama2.Transformer(\"/PATH/TO/YOUR.bin\");\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.TransformerWeights","page":"Home","title":"Llama2.TransformerWeights","text":"TransformerWeights\n\nCreate a TransformerWeights containing several Float32 containers. These describe actual weight data that is loaded from an input file.\n\nDeveloper Notes\n\nThis is an internal struct.\n\n\n\n\n\n","category":"type"},{"location":"#Llama2.compare_tokens-Tuple{TokenIndex, TokenIndex}","page":"Home","title":"Llama2.compare_tokens","text":"compare_tokens(first_token::TokenIndex, second_token::TokenIndex) -> Bool\n\nCompare two TokenIndex objects by their string values. It returns true if the first token's string is lexicographically less than the second's, and false otherwise.\n\nExamples\n\njulia> using Llama2;\n\njulia> compare_tokens(TokenIndex(\"A\", 1), TokenIndex(\"B\", 2))\ntrue\n\njulia> compare_tokens(TokenIndex(\"B\", 1), TokenIndex(\"A\", 2))\nfalse\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.encode-Tuple{Tokenizer, String}","page":"Home","title":"Llama2.encode","text":"encode\n\nConverts a string text into a sequence of token IDs using a Tokenizer. First ensure the tokenizer's vocabulary is sorted, then encode each character into its corresponding ID. After that, iteratively merge token pairs with the highest scores to form longer tokens until no more merges are possible. Return the final token ID sequence.\n\n\n\n\n\n","category":"method"},{"location":"#Llama2.str_lookup-Tuple{String, Vector{TokenIndex}}","page":"Home","title":"Llama2.str_lookup","text":"str_lookup(str::String, sorted_vocab::Vector{TokenIndex}) -> Int16\n\nSearch for a given string str within a sorted vocabulary sorted_vocab of TokenIndex objects. If the string is found, it returns the corresponding token ID; otherwise, it returns -1. It uses a binary search for efficient lookup.\n\nExamples\n\njulia> using Llama2;\n\njulia> str_lookup(\"aa\", [TokenIndex(\"aa\", 1), TokenIndex(\"bb\", 2)])\n1\n\njulia> str_lookup(\"ba\", [TokenIndex(\"aa\", 1), TokenIndex(\"bb\", 2)])\n-1\n\n\n\n\n\n","category":"method"},{"location":"inference/#Inference","page":"Inference","title":"Inference","text":"","category":"section"},{"location":"inference/#Prequisites","page":"Inference","title":"Prequisites","text":"A model checkpoint is required. You can use your own or e.g. get the example file provided by karpathy:\n\nwget https://huggingface.co/karpathy/tinyllamas/resolve/main/stories15M.bin","category":"section"},{"location":"inference/#Inferencing","page":"Inference","title":"Inferencing","text":"We need more working code for this.","category":"section"}]
}
